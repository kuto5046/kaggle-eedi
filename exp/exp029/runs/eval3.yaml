# @package _global_
run_name: eval3
notes: "学習済みのemb model"
use_fold: 0

retrieval_model:
  # name: BAAI/bge-large-en-v1.5
  # use_foldを見ていないモデル
  name: ${path.output_dir}/${exp_name}/fold${use_fold}

llm_model:
  name: hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4

max_candidates: 50  # 1つの学習データに紐づける負例の候補数
vllm:
  model:
    gpu_memory_utilization: 0.90
    max_model_len: 2048
