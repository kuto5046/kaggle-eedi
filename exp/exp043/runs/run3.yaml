# @package _global_
run_name: run3
notes: "lora_alpha=64 candidate=100"
use_fold: 0

retrieval_model:
  name: dunzhang/stella_en_1.5B_v5
  use_lora: true
  lora:
    r: 64
    lora_alpha: 64

max_candidates: 100
negative_size: 10
trainer:
  epoch: 10
  batch_size: 64
  gradient_accumulation_steps: 1
  gradient_checkpointing: true
  learning_rate: 8e-6
