# @package _global_
run_name: run7
notes: 32b awqはautoawqがkaggleで動かないのでbnb4bitでやる 64batch
use_fold: 0

feature_version: ${exp_name}/run0
negative_size: 1
use_mask_pad_token: true
retrieval_model:
  base_name: Qwen/Qwen2.5-32B-Instruct
  use_lora: true
  is_quantized: true
  use_sentence_transformers: false
  lora:
    r: 64
    lora_alpha: 128
    lora_dropout: 0.05
    task_type: DEFAULT

trainer:
  epoch: 5
  batch_size: 64
  learning_rate: 1e-4
  weight_decay: 0.01
