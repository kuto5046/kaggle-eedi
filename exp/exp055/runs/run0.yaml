# @package _global_
run_name: run0
notes: LLM FT
use_fold: 0

retrieval_model:
  base_name: Qwen/Qwen2.5-32B-Instruct
  pretrained_path: ${path.output_dir}/exp053/run0
  use_lora: true
  is_quantized: true
  use_sentence_transformers: false
  batch_size: 64
  lora:
    r: 64
    lora_alpha: 128
    lora_dropout: 0.05
    task_type: DEFAULT

trainer:
  epoch: 5
  batch_size: 32
  learning_rate: 1e-4
